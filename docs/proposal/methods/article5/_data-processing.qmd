The acquired tabular data will be first standardized and coded as a flat text file to support an extensive compatibility with other software. The codebook of the dataset will be available as a JSON file, and serve the purpose as the complete metadata. Summarized metadata and short documentation are available as commented lines in the flat file. The complete documentation of an end-to-end data-analysis procedures are stored as an analytic pipeline in a make-like `R` script with a reproducibility instruction in a `README` file. All user-defined functions are adequately commented as a `docstring` and stored in a public repository to ensure transparency.

First, the data is cleaned based on completion also inclusion and exclusion criteria. Data is regarded incomplete in case of missing values, which might happen (not) at random. After checking for completion and criteria, the data is standardized based on the variables, i.e. to set a correct object type for each field. For nominal variables, the class level is defined and recorded in the metadata. For ordinal variables, the data is ordered according to its natural order. All numeric variables are treated as a float, except for time-stamp field which will be treated as a `POSIX` date time. Other fields are treated as a string with no particular level or order. Entry with missing values in the psychological outcome variables are discarded. All entries are grouped based on age in a 10-year interval, reflecting sub-group analysis of major depressive disorder prevalence reported in Riskesdas 2018.

Second, psychological outcomes as a dependent variable (DV) are scored. The initial scoring for all psychological outcomes are solely intended for completing the missing-value analysis. Scoring are done by summing the dimensional/factor component of an instrument, as recommended by its manual. No calculation of true score or weight-adjusted score is considered for the initial scoring. The obtained initial score will be labeled as a raw score, which provide a rough estimate of the true underlying latent score.

Third, missing data is labelled row-wise as a new variable and further analyzed. To determine the mechanism of missingness, the variable signifying missing entry is cross-tabulated with each DV and tested for statistical significance using a $\chi^2$ test. To reduce the family-wise error rate when detecting non-random missing value generating process, Bonferroni correction is applied to the acquired p-values. If missingness happened at random, simple imputation method with central value would suffice. On the other hand, if missingness happened not at random, multiple imputation with chained equation will be performed to fill in the missing entry.

Fourth, the true score of psychological outcomes is estimated by calculating the plausible values from the factor scores. To obtain the factor score, the items from each psychometric instrument is fitted to create latent-variable models. These model are tested for its goodness of fit by evaluating the Akaike Information Criteria (AIC), Random Mean Squared Error of Approximation (RMSEA), Comparative-Fit Index (CFI), Tucker-Lewis Index (TLI), and Standardized Root Mean Squared Residual (SRMR). For a fit model, an asymptotic sampling covariance matrix is extracted from the estimated factor scores. Using 1,000 iterations, a set of values is drawn from the sampling distribution of the factor scores; the mean of drawn values are regarded as the true score.

Fifth, a sampling procedure is applied to the cleaned dataset, with the intention of preserving a realistic proportion of people affected by major depressive disorder. An online survey following convenient sampling technique is likely to suffer from participation bias, where the obtained response may not completely reflect the general population. The primary objective of this research is to assess the state resilience, hypothesized as the residuals obtained from a linear model of stressors in predicting psychological outcomes. As such, it is important to adjust the ratio of psychological outcomes to the estimated prevalence in the population. For this purpose, reports from Riskesdas in 2018 is used, where the prevalence of depression in each age groups is used as a standard reference. To perform sampling from the acquired responses, a random set of responses is drawn from the response pool while keeping the ratio of depressed-to-non-depressed subjects. The number of samples being drawn satisfies the minimum required samples in each sub-group, and the ratio of each sub-group is adjusted based on population census data. This sampling procedure is repeated with replacement for 1,000 times, and state resilience is calculated independently in each iteration.

Sixth, for each sampled subset, the score of state resilience is calculated following a recommendation by @Hltge2022. Principal component analysis (PCA) is performed independently to a set of independent variables (IV) and DV. In this case, IV comprises general stressors and health-related stressors; while DV comprises the true scores obtained from psychometric instruments. From these two PCA models, the first principal components ($PC$) of IV and DV are subsequently extracted. $PC_{IV}$ is then fitted to linear model to predict the $PC_{DV}$, where residuals of the model will be extracted. Using residual approach to measure resilience can be misleading in case of outliers, which may skew the model and produce biased residuals. To improve model robustness, two additional steps are implemented: (1) calculate the Cook's distance of the extracted residuals, then remove the identified outliers; and (2) use a robust correlation matrix when refitting the PCA model after removing outliers. State resilience is represented as the obtained residual, where the mean of resilience score is calculated per entry and imputed back to the original dataset.
